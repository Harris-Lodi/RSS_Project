{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit",
   "display_name": "Python 3.8.5 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "1baa965d5efe3ac65b79dfc60c0d706280b1da80fedb7760faf2759126c4f253"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Description: This notebook is to be used to test the process of converting entries from JSON files to one Pandas Dataframe, convert that dataframe to a CSV file, and then convert the CSV file to SQLite3 database!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pandas import DataFrame \n",
    "import json \n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"Json_Files/Luke/main.json\")\n",
    "items = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries = items[\"entries\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = entries[1][\"link\"]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = entries[1][\"id\"]\n",
    "test1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = len(entries)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID = []\n",
    "Link = []\n",
    "Name = []\n",
    "Date = []\n",
    "Summary = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in range(len(entries)):\n",
    "\n",
    "    # clean summary text with BS4\n",
    "    raw_html = entries[id][\"summary\"]\n",
    "    cleantext = BeautifulSoup(raw_html, \"lxml\").text\n",
    "    \n",
    "    # try setting link to 'link' key from JSON, if keyerror, use 'id', else \"N/A\"\n",
    "    try:\n",
    "        link = entries[id][\"link\"]\n",
    "    except KeyError:\n",
    "        link = entries[id][\"id\"]\n",
    "    except:\n",
    "        link = \"N/A\"\n",
    "\n",
    "    ID.append(id)\n",
    "    Link.append(link)\n",
    "    Name.append(entries[id][\"title\"])\n",
    "    Date.append(entries[id][\"published\"])\n",
    "    Summary.append(cleantext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "JSON_Dict = {\n",
    "    'ID': ID,\n",
    "    'Titles': Name,\n",
    "    'Published': Date,\n",
    "    'Link': Link,\n",
    "    'Summary': Summary,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = DataFrame(JSON_Dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# saving the DataFrame as a CSV file \n",
    "gfg_csv_data = df.to_csv('test.csv', index = True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a database or connect to one\n",
    "conn = sqlite3.connect('test.db')\n",
    "# Create cursor\n",
    "c = conn.cursor()\n",
    "c.execute(\"DROP TABLE IF EXISTS test\")\n",
    "c.execute(\"\"\"CREATE TABLE IF NOT EXISTS test (\n",
    "        ID INTEGER, \n",
    "        Titles TEXT, \n",
    "        Published TEXT, \n",
    "        Link TEXT,\n",
    "        Summary TEXT\n",
    "        ) \"\"\")\n",
    "#Commit Changes\n",
    "conn.commit()\n",
    "# Close Connection \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a database or connect to one\n",
    "conn = sqlite3.connect('test.db')\n",
    "# Create cursor\n",
    "c = conn.cursor()\n",
    "# convert dataframe to sql\n",
    "df.to_sql('test', conn, if_exists='replace', index=False)\n",
    "# Commit Changes\n",
    "conn.commit()\n",
    "# Close Connection \n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}